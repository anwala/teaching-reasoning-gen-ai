# Prompt Engineering

## Introduction

Prompts are how we interact with LLMs. [Prompt engineering is the process of creating effective prompts that guide a model toward desired outputs without expanding its knowledge base](https://www.ibm.com/think/topics/rag-vs-fine-tuning-vs-prompt-engineering#7281537). The quality of the response of an LLM is affected by the quality of the prompt. Which makes learning about prompt engineering crucial.

Here we will learn the fundamentals of prompt engineering. This includes the components of a prompt, how to design effective prompt, and the types of prompt.

## Concepts

* Part 1: [Introduction](https://www.promptingguide.ai/introduction) and [Risks & Misuses - Adversarial Prompting in LLMs](https://www.promptingguide.ai/risks)
* Part 2: [Prompting Techniques](https://www.promptingguide.ai/techniques)
* Part 3: [Prompt hub](https://www.promptingguide.ai/prompts) and Wild Card Prompt Engineering Topics

> Adversarial Prompting: Please note that we don't condone any of the attacks described in [Adversarial Prompting in LLMs](https://www.promptingguide.ai/risks). It is provided for educational purposes and to highlight the limitations of LLMs. If you choose to test the limitations of LLMs (of course for academic reasons), I'll advise you to use a dummy account just in case it gets suspended. Also note that LLMs are always being improved, so previously found "bug" might not work.

## In-class group task 1:
Identify a specific problem in a domain you care about (e.g., Health, Education, Entertainment, Business). Design a prompt using one of the specified patterns (zero vs. few-shot) just discussed to instruct an LLM of your choice to solve the problem.

Present your findings (starting with problem domain, problem, and LLM) and answer the following questions:
1. Are you satisfied with the solution? Why?
2. Provide justification for the prompt pattern you choose
3. How did you arrive at your final prompt (show the evolution of your prompt)
4. How did you evaluate the response of the LLM
5. Provide additional feedback
6. Outside-class group activity 

## Outside-class group activity:

Explore all prompt domain areas in [LLM prompt hub](https://www.promptingguide.ai/prompts) and experiment with the prompts. Select one domain (e.g., Information Extraction or Classification) and apply the approach from LLM prompt hub to your own data. Next time we meet you will address the following:

Present your findings (starting with problem domain, problem, and LLM) and answer the following questions:
1. Are you satisfied with the solution? Why?
2. Provide justification for the prompt pattern you choose
3. How did you arrive at your final prompt (show the evolution of your prompt)
4. How did you evaluate the response of the LLM
5. Provide additional feedback
